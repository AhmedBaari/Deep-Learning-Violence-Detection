{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "006944ad",
   "metadata": {},
   "source": [
    "## CELL 1: Setup\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3db3dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 1: SETUP\n",
    "# ============================================================\n",
    "\n",
    "import os\n",
    "from pathlib import Path\n",
    "from datetime import datetime\n",
    "\n",
    "output_dir = Path('./novelty_implementation/ablation_scripts')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"NOTEBOOK 9B: DDP SCRIPT EXPORT\")\n",
    "print(\"=\"*80)\n",
    "print(f\"✓ Scripts will be exported to: {output_dir}\")\n",
    "print(f\"✓ Generation timestamp: {datetime.now().isoformat()}\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecc83c5b",
   "metadata": {},
   "source": [
    "## CELL 2: Generate DDP Script Template Function\n",
    "\n",
    "This function generates complete DDP training scripts based on component flags.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ca2171d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 2: DDP SCRIPT TEMPLATE GENERATOR\n",
    "# ============================================================\n",
    "\n",
    "def generate_ddp_script(config_name, config_dict):\n",
    "    \"\"\"\n",
    "    Generate a complete DDP training script.\n",
    "    \n",
    "    Args:\n",
    "        config_name: Name of configuration (e.g., '09_ViT_Aug_NSL_DDP')\n",
    "        config_dict: Configuration dictionary with component flags\n",
    "    \n",
    "    Returns:\n",
    "        Complete Python script as string\n",
    "    \"\"\"\n",
    "    \n",
    "    use_cbam = config_dict.get('use_cbam', False)\n",
    "    use_nsl = config_dict.get('use_nsl', False)\n",
    "    use_pgd = config_dict.get('use_pgd', False)\n",
    "    use_mixup = config_dict.get('use_mixup', False)\n",
    "    use_cutmix = config_dict.get('use_cutmix', False)\n",
    "    \n",
    "    script = f'''#!/usr/bin/env python3\n",
    "\\\"\"\"\n",
    "DDP Training Script: {config_name}\n",
    "Generated: {datetime.now().isoformat()}\n",
    "\n",
    "Usage:\n",
    "    torchrun --nproc_per_node=8 \\\\\\\\\n",
    "             --nnodes=1 \\\\\\\\\n",
    "             --node_rank=0 \\\\\\\\\n",
    "             --master_addr=\"localhost\" \\\\\\\\\n",
    "             --master_port=29500 \\\\\\\\\n",
    "             {config_name.lower().replace(\" \", \"_\")}.py\n",
    "\\\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "from pathlib import Path\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.distributed as dist\n",
    "from torch.nn.parallel import DistributedDataParallel as DDP\n",
    "from torch.utils.data import DataLoader, DistributedSampler, Dataset\n",
    "from torch.optim import AdamW\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR\n",
    "\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import timm\n",
    "\n",
    "RANDOM_SEED = 42\n",
    "\n",
    "# ============================================================\n",
    "# COMPONENT IMPLEMENTATIONS\n",
    "# ============================================================\n",
    "\n",
    "# Dataset class\n",
    "class HMDB51Dataset(Dataset):\n",
    "    def __init__(self, samples, indices, transform=None, return_neighbors=False, neighbor_indices=None):\n",
    "        self.samples = [samples[i] for i in indices]\n",
    "        self.transform = transform\n",
    "        self.return_neighbors = return_neighbors\n",
    "        self.neighbor_indices = neighbor_indices\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.samples[idx]\n",
    "        img_path = sample['path']\n",
    "        label = sample['label']\n",
    "        \n",
    "        image = Image.open(img_path).convert('RGB')\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        if self.return_neighbors and self.neighbor_indices is not None:\n",
    "            neighbors = self.neighbor_indices[idx]\n",
    "            return image, label, neighbors\n",
    "        \n",
    "        return image, label\n",
    "\n",
    "# Transforms\n",
    "def get_basic_aug_transform():\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((256, 256)),\n",
    "        transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),\n",
    "        transforms.RandomHorizontalFlip(p=0.5),\n",
    "        transforms.RandomRotation(degrees=10),\n",
    "        transforms.ColorJitter(brightness=0.2, contrast=0.2, saturation=0.2, hue=0.1),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "def get_val_transform():\n",
    "    return transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "    ])\n",
    "\n",
    "# MixUp & CutMix'''\n",
    "    \n",
    "    if use_mixup or use_cutmix:\n",
    "        script += '''\n",
    "def mixup_data(x, y, alpha=0.4):\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size, device=x.device)\n",
    "    mixed_x = lam * x + (1 - lam) * x[index]\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def rand_bbox(size, lam):\n",
    "    W, H = size[2], size[3]\n",
    "    cut_rat = np.sqrt(1. - lam)\n",
    "    cut_w, cut_h = int(W * cut_rat), int(H * cut_rat)\n",
    "    cx, cy = np.random.randint(W), np.random.randint(H)\n",
    "    bbx1 = np.clip(cx - cut_w // 2, 0, W)\n",
    "    bby1 = np.clip(cy - cut_h // 2, 0, H)\n",
    "    bbx2 = np.clip(cx + cut_w // 2, 0, W)\n",
    "    bby2 = np.clip(cy + cut_h // 2, 0, H)\n",
    "    return bbx1, bby1, bbx2, bby2\n",
    "\n",
    "def cutmix_data(x, y, alpha=1.0):\n",
    "    lam = np.random.beta(alpha, alpha)\n",
    "    batch_size = x.size(0)\n",
    "    index = torch.randperm(batch_size, device=x.device)\n",
    "    bbx1, bby1, bbx2, bby2 = rand_bbox(x.size(), lam)\n",
    "    mixed_x = x.clone()\n",
    "    mixed_x[:, :, bbx1:bbx2, bby1:bby2] = x[index, :, bbx1:bbx2, bby1:bby2]\n",
    "    lam = 1 - ((bbx2 - bbx1) * (bby2 - bby1) / (x.size(-1) * x.size(-2)))\n",
    "    y_a, y_b = y, y[index]\n",
    "    return mixed_x, y_a, y_b, lam\n",
    "\n",
    "def mixup_criterion(criterion, pred, y_a, y_b, lam):\n",
    "    return lam * criterion(pred, y_a) + (1 - lam) * criterion(pred, y_b)\n",
    "'''\n",
    "    \n",
    "    if use_nsl:\n",
    "        script += '''\n",
    "# NSL Loss\n",
    "def virtual_adversarial_loss(model, x, logits, xi=1e-6, eps=2.0, num_iters=1):\n",
    "    d = torch.randn_like(x, requires_grad=False)\n",
    "    d = d / (torch.norm(d.view(d.size(0), -1), dim=1, keepdim=True).unsqueeze(-1).unsqueeze(-1) + 1e-8)\n",
    "    \n",
    "    for _ in range(num_iters):\n",
    "        d = d.clone().detach().requires_grad_(True)\n",
    "        pred_hat = model(x + xi * d)\n",
    "        logp = F.log_softmax(pred_hat, dim=1)\n",
    "        p = F.softmax(logits.detach(), dim=1)\n",
    "        kl = F.kl_div(logp, p, reduction='batchmean')\n",
    "        kl.backward()\n",
    "        d = d.grad.data.clone()\n",
    "        d = d / (torch.norm(d.view(d.size(0), -1), dim=1, keepdim=True).unsqueeze(-1).unsqueeze(-1) + 1e-8)\n",
    "        model.zero_grad()\n",
    "    \n",
    "    r_adv = eps * d.detach()\n",
    "    pred_hat = model(x + r_adv)\n",
    "    logp_hat = F.log_softmax(pred_hat, dim=1)\n",
    "    p = F.softmax(logits.detach(), dim=1)\n",
    "    vat_loss = F.kl_div(logp_hat, p, reduction='batchmean')\n",
    "    return vat_loss\n",
    "'''\n",
    "    \n",
    "    if use_cbam:\n",
    "        script += '''\n",
    "# CBAM Attention\n",
    "class ChannelAttention(nn.Module):\n",
    "    def __init__(self, in_channels, reduction=16):\n",
    "        super().__init__()\n",
    "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
    "        self.max_pool = nn.AdaptiveMaxPool2d(1)\n",
    "        self.mlp = nn.Sequential(\n",
    "            nn.Linear(in_channels, in_channels // reduction, bias=False),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(in_channels // reduction, in_channels, bias=False)\n",
    "        )\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        b, c, _, _ = x.size()\n",
    "        avg_out = self.mlp(self.avg_pool(x).view(b, c))\n",
    "        max_out = self.mlp(self.max_pool(x).view(b, c))\n",
    "        attention = self.sigmoid(avg_out + max_out).view(b, c, 1, 1)\n",
    "        return x * attention\n",
    "\n",
    "class SpatialAttention(nn.Module):\n",
    "    def __init__(self, kernel_size=7):\n",
    "        super().__init__()\n",
    "        padding = kernel_size // 2\n",
    "        self.conv = nn.Conv2d(2, 1, kernel_size, padding=padding, bias=False)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        avg_out = x.mean(dim=1, keepdim=True)\n",
    "        max_out = x.max(dim=1, keepdim=True)[0]\n",
    "        combined = torch.cat([avg_out, max_out], dim=1)\n",
    "        attention = self.sigmoid(self.conv(combined))\n",
    "        return x * attention\n",
    "\n",
    "class CBAM(nn.Module):\n",
    "    def __init__(self, in_channels, reduction=16, kernel_size=7):\n",
    "        super().__init__()\n",
    "        self.channel_attention = ChannelAttention(in_channels, reduction)\n",
    "        self.spatial_attention = SpatialAttention(kernel_size)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.channel_attention(x)\n",
    "        x = self.spatial_attention(x)\n",
    "        return x\n",
    "\n",
    "class ViTWithCBAM(nn.Module):\n",
    "    def __init__(self, num_classes=8, pretrained=True):\n",
    "        super().__init__()\n",
    "        self.vit = timm.create_model('vit_base_patch16_224', pretrained=pretrained)\n",
    "        hidden_dim = self.vit.head.in_features\n",
    "        self.vit.head = nn.Identity()\n",
    "        self.cbam = CBAM(hidden_dim, reduction=16)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(hidden_dim, 512),\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Dropout(0.3),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        features = self.vit.forward_features(x)\n",
    "        cls_token = features[:, 0]\n",
    "        cls_reshaped = cls_token.unsqueeze(-1).unsqueeze(-1)\n",
    "        attended = self.cbam(cls_reshaped)\n",
    "        attended = attended.squeeze(-1).squeeze(-1)\n",
    "        out = self.classifier(attended)\n",
    "        return out\n",
    "'''\n",
    "    \n",
    "    if use_pgd:\n",
    "        script += '''\n",
    "# PGD Adversarial Attack\n",
    "def pgd_attack(model, images, labels, eps=8/255, alpha=2/255, num_steps=7, random_start=True):\n",
    "    images = images.clone().detach()\n",
    "    adv_images = images.clone().detach()\n",
    "    \n",
    "    if random_start:\n",
    "        adv_images = adv_images + torch.empty_like(adv_images).uniform_(-eps, eps)\n",
    "        adv_images = torch.clamp(adv_images, 0, 1)\n",
    "    \n",
    "    for _ in range(num_steps):\n",
    "        adv_images.requires_grad = True\n",
    "        outputs = model(adv_images)\n",
    "        loss = F.cross_entropy(outputs, labels)\n",
    "        grad = torch.autograd.grad(loss, adv_images, retain_graph=False, create_graph=False)[0]\n",
    "        adv_images = adv_images.detach() + alpha * grad.sign()\n",
    "        delta = torch.clamp(adv_images - images, -eps, eps)\n",
    "        adv_images = torch.clamp(images + delta, 0, 1)\n",
    "    \n",
    "    return adv_images.detach()\n",
    "'''\n",
    "    \n",
    "    # Main function\n",
    "    epochs = config_dict.get('epochs', 15)\n",
    "    batch_size = config_dict.get('batch_size', 64)\n",
    "    lr = config_dict.get('learning_rate', 1e-4)\n",
    "    \n",
    "    script += f'''\n",
    "# ============================================================\n",
    "# MAIN DDP TRAINING\n",
    "# ============================================================\n",
    "\n",
    "def main():\n",
    "    # DDP Setup\n",
    "    dist.init_process_group(backend=\"nccl\")\n",
    "    local_rank = int(os.environ[\"LOCAL_RANK\"])\n",
    "    world_size = dist.get_world_size()\n",
    "    torch.cuda.set_device(local_rank)\n",
    "    device = torch.device(f\"cuda:{{local_rank}}\")\n",
    "    \n",
    "    is_main = local_rank == 0\n",
    "    \n",
    "    if is_main:\n",
    "        print(\"=\"*80)\n",
    "        print(f\"ABLATION: {config_name}\")\n",
    "        print(\"=\"*80)\n",
    "        print(f\"World Size: {{world_size}} GPUs\")\n",
    "        print(f\"Configuration: {config_dict}\")\n",
    "    \n",
    "    # Set seeds\n",
    "    torch.manual_seed(RANDOM_SEED + local_rank)\n",
    "    np.random.seed(RANDOM_SEED + local_rank)\n",
    "    random.seed(RANDOM_SEED + local_rank)\n",
    "    \n",
    "    # Load data\n",
    "    BASE_DIR = Path('./novelty_files')\n",
    "    with open(BASE_DIR / 'splits' / 'train_indices.pkl', 'rb') as f:\n",
    "        train_indices = pickle.load(f)\n",
    "    with open(BASE_DIR / 'splits' / 'val_indices.pkl', 'rb') as f:\n",
    "        val_indices = pickle.load(f)\n",
    "    \n",
    "    # Load samples\n",
    "    class HMDB51FightDataset(Dataset):\n",
    "        def __init__(self, root_dir, split, class_to_idx):\n",
    "            self.root_dir = Path(root_dir)\n",
    "            self.samples = []\n",
    "            split_dir = self.root_dir / split\n",
    "            for class_name, class_idx in class_to_idx.items():\n",
    "                class_dir = split_dir / class_name\n",
    "                if class_dir.exists():\n",
    "                    for img_path in list(class_dir.glob('*.jpg')) + list(class_dir.glob('*.png')):\n",
    "                        self.samples.append({{'path': str(img_path), 'label': class_idx, 'class_name': class_name}})\n",
    "        def __len__(self):\n",
    "            return len(self.samples)\n",
    "    \n",
    "    with open(BASE_DIR / 'splits' / 'class_distribution.json') as f:\n",
    "        dist_data = json.load(f)\n",
    "    class_to_idx = dist_data['class_to_idx']\n",
    "    \n",
    "    dataset_path = './fight_dataset/actions (2)/actions'\n",
    "    train_loader_temp = HMDB51FightDataset(dataset_path, 'train', class_to_idx)\n",
    "    test_loader_temp = HMDB51FightDataset(dataset_path, 'test', class_to_idx)\n",
    "    all_samples = train_loader_temp.samples + test_loader_temp.samples\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = HMDB51Dataset(all_samples, train_indices, transform=get_basic_aug_transform())\n",
    "    val_dataset = HMDB51Dataset(all_samples, val_indices, transform=get_val_transform())\n",
    "    \n",
    "    # Create distributed samplers\n",
    "    train_sampler = DistributedSampler(train_dataset, num_replicas=world_size, rank=local_rank, shuffle=True)\n",
    "    val_sampler = DistributedSampler(val_dataset, num_replicas=world_size, rank=local_rank, shuffle=False)\n",
    "    \n",
    "    # Create dataloaders\n",
    "    train_loader = DataLoader(train_dataset, batch_size={batch_size}, sampler=train_sampler, num_workers=4, pin_memory=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size={batch_size}, sampler=val_sampler, num_workers=4, pin_memory=True)\n",
    "    \n",
    "    if is_main:\n",
    "        print(f\"✓ Train: {{len(train_loader)}} batches/GPU × {{world_size}} GPUs\")\n",
    "        print(f\"✓ Val: {{len(val_loader)}} batches/GPU × {{world_size}} GPUs\")\n",
    "    \n",
    "    # Create model\n",
    "    {'model = ViTWithCBAM(num_classes=8)' if use_cbam else 'model = timm.create_model(\"vit_base_patch16_224\", pretrained=True, num_classes=8)'}\n",
    "    model = model.to(device)\n",
    "    model = DDP(model, device_ids=[local_rank])\n",
    "    \n",
    "    # Optimizer and scheduler\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = AdamW(model.parameters(), lr={lr}, weight_decay=1e-4)\n",
    "    scheduler = CosineAnnealingLR(optimizer, T_max={epochs})\n",
    "    \n",
    "    # Training loop\n",
    "    best_val_acc = 0.0\n",
    "    checkpoint_path = BASE_DIR / 'checkpoints' / 'ablation' / '{config_name}.pt'\n",
    "    checkpoint_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "    \n",
    "    for epoch in range({epochs}):\n",
    "        train_sampler.set_epoch(epoch)\n",
    "        model.train()\n",
    "        \n",
    "        train_loss = 0.0\n",
    "        train_correct = 0\n",
    "        train_total = 0\n",
    "        \n",
    "        for batch_idx, (images, labels) in enumerate(train_loader):\n",
    "            images, labels = images.to(device), labels.to(device)\n",
    "            \n",
    "            '''\n",
    "    \n",
    "    # Add training logic based on components\n",
    "    if use_pgd:\n",
    "        script += '''\n",
    "            # PGD adversarial training\n",
    "            model.eval()\n",
    "            adv_images = pgd_attack(model, images, labels)\n",
    "            model.train()\n",
    "            \n",
    "            clean_outputs = model(images)\n",
    "            adv_outputs = model(adv_images)\n",
    "            \n",
    "            clean_loss = criterion(clean_outputs, labels)\n",
    "            adv_loss = criterion(adv_outputs, labels)\n",
    "            loss = 0.5 * clean_loss + 0.5 * adv_loss\n",
    "            outputs = clean_outputs\n",
    "'''\n",
    "    elif use_mixup or use_cutmix:\n",
    "        script += '''\n",
    "            # MixUp/CutMix augmentation\n",
    "            if np.random.random() < 0.5:\n",
    "                images, labels_a, labels_b, lam = mixup_data(images, labels)\n",
    "                outputs = model(images)\n",
    "                loss = mixup_criterion(criterion, outputs, labels_a, labels_b, lam)\n",
    "            else:\n",
    "                outputs = model(images)\n",
    "                loss = criterion(outputs, labels)\n",
    "'''\n",
    "    else:\n",
    "        script += '''\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "'''\n",
    "    \n",
    "    if use_nsl:\n",
    "        script += '''\n",
    "            # Add NSL loss\n",
    "            vat_loss = virtual_adversarial_loss(model, images, outputs)\n",
    "            loss = loss + 1.0 * vat_loss\n",
    "'''\n",
    "    \n",
    "    script += '''\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
    "            optimizer.step()\n",
    "            \n",
    "            train_loss += loss.item()\n",
    "            _, predicted = outputs.max(1)\n",
    "            train_total += labels.size(0)\n",
    "            train_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        # Validation\n",
    "        model.eval()\n",
    "        val_correct = 0\n",
    "        val_total = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in val_loader:\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                _, predicted = outputs.max(1)\n",
    "                val_total += labels.size(0)\n",
    "                val_correct += predicted.eq(labels).sum().item()\n",
    "        \n",
    "        # Gather metrics\n",
    "        train_loss_tensor = torch.tensor([train_loss / len(train_loader)], device=device)\n",
    "        val_correct_tensor = torch.tensor([val_correct], device=device)\n",
    "        val_total_tensor = torch.tensor([val_total], device=device)\n",
    "        \n",
    "        dist.all_reduce(train_loss_tensor, op=dist.ReduceOp.SUM)\n",
    "        dist.all_reduce(val_correct_tensor, op=dist.ReduceOp.SUM)\n",
    "        dist.all_reduce(val_total_tensor, op=dist.ReduceOp.SUM)\n",
    "        \n",
    "        avg_train_loss = (train_loss_tensor / world_size).item()\n",
    "        val_acc = 100.0 * val_correct_tensor.item() / val_total_tensor.item()\n",
    "        train_acc = 100.0 * train_correct / train_total\n",
    "        \n",
    "        scheduler.step()\n",
    "        \n",
    "        if is_main:\n",
    "            print(f\"Epoch {{epoch+1}}/{epochs}: Train Loss={{avg_train_loss:.4f}}, Train Acc={{train_acc:.2f}}%, Val Acc={{val_acc:.2f}}%\")\n",
    "            \n",
    "            if val_acc > best_val_acc:\n",
    "                best_val_acc = val_acc\n",
    "                checkpoint = {{\n",
    "                    'epoch': epoch + 1,\n",
    "                    'model_state_dict': model.module.state_dict(),\n",
    "                    'optimizer_state_dict': optimizer.state_dict(),\n",
    "                    'val_accuracy': val_acc,\n",
    "                    'config': {config_dict}\n",
    "                }}\n",
    "                torch.save(checkpoint, checkpoint_path)\n",
    "                print(f\"✓ Best model saved (val_acc={{val_acc:.2f}}%)\")\n",
    "    \n",
    "    if is_main:\n",
    "        print(f\"\\\\nTraining complete! Best val acc: {{best_val_acc:.2f}}%\")\n",
    "    \n",
    "    dist.destroy_process_group()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    main()\n",
    "'''\n",
    "    \n",
    "    return script\n",
    "\n",
    "print(\"✓ DDP script generator function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad4a451b",
   "metadata": {},
   "source": [
    "## CELL 3: Export Config 09 - ViT + Aug + NSL (DDP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2703c73d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 3: EXPORT CONFIG 09 (ViT + Aug + NSL + DDP)\n",
    "# ============================================================\n",
    "\n",
    "config_09 = {\n",
    "    'name': '09_ViT_Aug_NSL_DDP',\n",
    "    'model_type': 'vit',\n",
    "    'epochs': 3,\n",
    "    'batch_size': 64,\n",
    "    'learning_rate': 1e-4,\n",
    "    'use_basicaug': True,\n",
    "    'use_mixup': True,\n",
    "    'use_cutmix': True,\n",
    "    'use_nsl': True,\n",
    "    'use_cbam': False,\n",
    "    'use_pgd': False\n",
    "}\n",
    "\n",
    "script_09 = generate_ddp_script(\n",
    "    config_09['name'],\n",
    "    config_09\n",
    ")\n",
    "\n",
    "script_path_09 = output_dir / 'ablation_ddp_09.py'\n",
    "with open(script_path_09, 'w') as f:\n",
    "    f.write(script_09)\n",
    "\n",
    "print(\\\"=\\\"*80)\n",
    "print(\\\"CONFIG 09: ViT + Aug + NSL (DDP)\\\")\n",
    "print(\\\"=\\\"*80)\n",
    "print(f\\\"✓ Exported: {script_path_09}\\\")\n",
    "print(f\\\"✓ Size: {len(script_09)} characters\\\")\n",
    "print(f\\\"\\\\nRun with:\\\")\n",
    "print(f\\\"  cd {output_dir.parent}\\\")\n",
    "print(f\\\"  torchrun --nproc_per_node=8 ablation_scripts/ablation_ddp_09.py\\\")\n",
    "print(f\\\"\\\\nExpected runtime: ~6-8 hours on 8× H200 GPUs\\\")\n",
    "print(f\\\"Expected accuracy: ~84-86%\\\")\n",
    "print(\\\"=\\\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "371a1087",
   "metadata": {},
   "source": [
    "## CELL 4: Export Config 14 - Full Pipeline (Single GPU)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ccfc651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 4: EXPORT CONFIG 14 (Full Pipeline - Single GPU Baseline)\n",
    "# ============================================================\n",
    "\n",
    "config_14 = {\n",
    "    'name': '14_ViT_CBAM_Aug_NSL_PGD',\n",
    "    'model_type': 'vit',\n",
    "    'epochs': 3,\n",
    "    'batch_size': 32,  # Smaller batch for single GPU + all components\n",
    "    'learning_rate': 1e-4,\n",
    "    'use_basicaug': True,\n",
    "    'use_mixup': True,\n",
    "    'use_cutmix': True,\n",
    "    'use_nsl': True,\n",
    "    'use_cbam': True,\n",
    "    'use_pgd': True\n",
    "}\n",
    "\n",
    "# Generate single GPU version (no DDP)\n",
    "script_14 = generate_ddp_script(config_14['name'], config_14)\n",
    "\n",
    "# Remove DDP code for single GPU version\n",
    "script_14_single = script_14.replace(\n",
    "    'import torch.distributed as dist\\\\nfrom torch.nn.parallel import DistributedDataParallel as DDP',\n",
    "    '# Single GPU mode - no DDP needed'\n",
    ").replace(\n",
    "    '    dist.init_process_group(backend=\\\"nccl\\\")',\n",
    "    '    # Single GPU - skip DDP init'\n",
    ").replace(\n",
    "    '    local_rank = int(os.environ[\\\"LOCAL_RANK\\\"])',\n",
    "    '    local_rank = 0'\n",
    ").replace(\n",
    "    '    world_size = dist.get_world_size()',\n",
    "    '    world_size = 1'\n",
    ").replace(\n",
    "    '    model = DDP(model, device_ids=[local_rank])',\n",
    "    '    # Single GPU - no DDP wrapping'\n",
    ").replace(\n",
    "    '    dist.all_reduce',\n",
    "    '    # dist.all_reduce'\n",
    ").replace(\n",
    "    '    dist.destroy_process_group()',\n",
    "    '    # No DDP to destroy'\n",
    ").replace(\n",
    "    'model.module.state_dict()',\n",
    "    'model.state_dict()'\n",
    ")\n",
    "\n",
    "script_path_14 = output_dir / 'ablation_single_14.py'\n",
    "with open(script_path_14, 'w') as f:\n",
    "    f.write(script_14_single)\n",
    "\n",
    "print(\\\"=\\\"*80)\n",
    "print(\\\"CONFIG 14: Full Pipeline (Single GPU Baseline)\\\")\n",
    "print(\\\"=\\\"*80)\n",
    "print(f\\\"✓ Exported: {script_path_14}\\\")\n",
    "print(f\\\"✓ Size: {len(script_14_single)} characters\\\")\n",
    "print(f\\\"\\\\nRun with:\\\")\n",
    "print(f\\\"  cd {output_dir.parent}\\\")\n",
    "print(f\\\"  python ablation_scripts/ablation_single_14.py\\\")\n",
    "print(f\\\"\\\\nExpected runtime: ~10-12 hours on single GPU\\\")\n",
    "print(f\\\"Expected accuracy: ~86-88%\\\")\n",
    "print(f\\\"Note: This provides single-GPU baseline for comparison with DDP Config 15\\\")\n",
    "print(\\\"=\\\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c180bea",
   "metadata": {},
   "source": [
    "## CELL 5: Export Config 15 - Full Pipeline (DDP)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cee2c234",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 5: EXPORT CONFIG 15 (Full Pipeline + DDP)\n",
    "# ============================================================\n",
    "\n",
    "config_15 = {\n",
    "    'name': '15_FULL_PIPELINE',\n",
    "    'model_type': 'vit',\n",
    "    'epochs': 3,\n",
    "    'batch_size': 64,\n",
    "    'learning_rate': 1e-4,\n",
    "    'use_basicaug': True,\n",
    "    'use_mixup': True,\n",
    "    'use_cutmix': True,\n",
    "    'use_nsl': True,\n",
    "    'use_cbam': True,\n",
    "    'use_pgd': True  # Note: PGD with DDP - most comprehensive\n",
    "}\n",
    "\n",
    "script_15 = generate_ddp_script(\n",
    "    config_15['name'],\n",
    "    config_15\n",
    ")\n",
    "\n",
    "script_path_15 = output_dir / 'ablation_ddp_15.py'\n",
    "with open(script_path_15, 'w') as f:\n",
    "    f.write(script_15)\n",
    "\n",
    "print(\\\"=\\\"*80)\n",
    "print(\\\"CONFIG 15: Full Pipeline (DDP)\\\")\n",
    "print(\\\"=\\\"*80)\n",
    "print(f\\\"✓ Exported: {script_path_15}\\\")\n",
    "print(f\\\"✓ Size: {len(script_15)} characters\\\")\n",
    "print(f\\\"\\\\nRun with:\\\")\n",
    "print(f\\\"  cd {output_dir.parent}\\\")\n",
    "print(f\\\"  torchrun --nproc_per_node=8 --master_port=29501 ablation_scripts/ablation_ddp_15.py\\\")\n",
    "print(f\\\"\\\\nExpected runtime: ~8-10 hours on 8× H200 GPUs\\\")\n",
    "print(f\\\"Expected accuracy: ~87-90% (TARGET GOAL)\\\")\n",
    "print(f\\\"Note: Uses different port (29501) to avoid conflicts with Config 09\\\")\n",
    "print(\\\"=\\\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49f4d29d",
   "metadata": {},
   "source": [
    "## CELL 6: Create Execution README\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be171e1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 6: CREATE EXECUTION README\n",
    "# ============================================================\n",
    "\n",
    "readme_content = '''# DDP Ablation Execution Guide\n",
    "\n",
    "## Scripts Generated\n",
    "\n",
    "- `ablation_ddp_09.py` - Config 09: ViT + Aug + NSL + DDP\n",
    "- `ablation_single_14.py` - Config 14: Full Pipeline (Single GPU)\n",
    "- `ablation_ddp_15.py` - Config 15: Full Pipeline + DDP\n",
    "\n",
    "## Prerequisites\n",
    "\n",
    "```bash\n",
    "# Ensure 8 GPUs are available\n",
    "nvidia-smi\n",
    "\n",
    "# Check DDP environment\n",
    "python -c \\\"import torch; print(f'GPUs: {torch.cuda.device_count()}, DDP: {torch.distributed.is_available()}')\\\"\n",
    "\n",
    "# Verify NCCL backend\n",
    "python -c \\\"import torch.distributed as dist; print(f'NCCL: {dist.is_nccl_available()}')\\\"\n",
    "```\n",
    "\n",
    "## Execution\n",
    "\n",
    "### Config 09: ViT + Aug + NSL (DDP - 8 GPUs)\n",
    "\n",
    "**Expected:** ~84-86% validation accuracy  \n",
    "**Runtime:** ~6-8 hours on 8× H200 GPUs\n",
    "\n",
    "```bash\n",
    "cd novelty_implementation\n",
    "\n",
    "torchrun --nproc_per_node=8 \\\\\n",
    "         --nnodes=1 \\\\\n",
    "         --node_rank=0 \\\\\n",
    "         --master_addr=\\\"localhost\\\" \\\\\n",
    "         --master_port=29500 \\\\\n",
    "         ablation_scripts/ablation_ddp_09.py\n",
    "```\n",
    "\n",
    "### Config 14: Full Pipeline (Single GPU Baseline)\n",
    "\n",
    "**Expected:** ~86-88% validation accuracy  \n",
    "**Runtime:** ~10-12 hours on single GPU  \n",
    "**Purpose:** Single-GPU baseline for comparison with DDP Config 15\n",
    "\n",
    "```bash\n",
    "cd novelty_implementation\n",
    "\n",
    "python ablation_scripts/ablation_single_14.py\n",
    "```\n",
    "\n",
    "### Config 15: Full Pipeline (DDP - 8 GPUs) - TARGET GOAL\n",
    "\n",
    "**Expected:** ~87-90% validation accuracy (PROJECT GOAL)  \n",
    "**Runtime:** ~8-10 hours on 8× H200 GPUs\n",
    "\n",
    "```bash\n",
    "cd novelty_implementation\n",
    "\n",
    "torchrun --nproc_per_node=8 \\\\\n",
    "         --nnodes=1 \\\\\n",
    "         --node_rank=0 \\\\\n",
    "         --master_addr=\\\"localhost\\\" \\\\\n",
    "         --master_port=29501 \\\\\n",
    "         ablation_scripts/ablation_ddp_15.py\n",
    "```\n",
    "\n",
    "**Note:** Uses port 29501 to avoid conflicts with Config 09\n",
    "\n",
    "## Monitoring\n",
    "\n",
    "### GPU Usage\n",
    "```bash\n",
    "# Watch GPU usage (update every 1 second)\n",
    "watch -n 1 nvidia-smi\n",
    "\n",
    "# More detailed monitoring\n",
    "nvidia-smi dmon -s pucvmet\n",
    "```\n",
    "\n",
    "### Training Progress\n",
    "```bash\n",
    "# If running in background with nohup\n",
    "tail -f nohup.out\n",
    "\n",
    "# Or use screen/tmux for persistent sessions\n",
    "screen -S ablation_09\n",
    "# Then run torchrun command\n",
    "# Detach: Ctrl+A, D\n",
    "# Reattach: screen -r ablation_09\n",
    "```\n",
    "\n",
    "## Checkpoints\n",
    "\n",
    "All checkpoints are saved to:\n",
    "```\n",
    "novelty_files/checkpoints/ablation/\n",
    "├── 09_ViT_Aug_NSL_DDP.pt\n",
    "├── 14_ViT_CBAM_Aug_NSL_PGD.pt\n",
    "└── 15_FULL_PIPELINE.pt\n",
    "```\n",
    "\n",
    "Each checkpoint includes:\n",
    "- `model_state_dict`: Model weights\n",
    "- `optimizer_state_dict`: Optimizer state\n",
    "- `val_accuracy`: Best validation accuracy\n",
    "- `epoch`: Training epoch\n",
    "- `config`: Configuration dictionary\n",
    "\n",
    "## Troubleshooting\n",
    "\n",
    "### Issue: NCCL timeout or communication error\n",
    "\n",
    "**Solution:**\n",
    "```bash\n",
    "export NCCL_DEBUG=INFO\n",
    "export NCCL_IB_DISABLE=0\n",
    "export NCCL_SOCKET_IFNAME=eth0  # Adjust to your network interface\n",
    "```\n",
    "\n",
    "### Issue: Out of memory (OOM)\n",
    "\n",
    "**Solution:** Reduce batch size in the script:\n",
    "- Edit `batch_size=64` → `batch_size=32` in the script\n",
    "- Regenerate or manually edit the .py file\n",
    "\n",
    "### Issue: Port already in use\n",
    "\n",
    "**Solution:** Change the port number:\n",
    "```bash\n",
    "--master_port=29502  # Use a different port\n",
    "```\n",
    "\n",
    "### Issue: Different number of GPUs\n",
    "\n",
    "**Solution:** Adjust `--nproc_per_node`:\n",
    "```bash\n",
    "torchrun --nproc_per_node=4 ...  # For 4 GPUs\n",
    "```\n",
    "\n",
    "## Expected Timeline\n",
    "\n",
    "| Config | Type | Runtime | Expected Acc |\n",
    "|--------|------|---------|--------------|\n",
    "| 09 | DDP (8 GPU) | 6-8 hours | ~84-86% |\n",
    "| 14 | Single GPU | 10-12 hours | ~86-88% |\n",
    "| 15 | DDP (8 GPU) | 8-10 hours | ~87-90% ✓ |\n",
    "\n",
    "**Total estimated time:** ~24-30 hours (if run sequentially)  \n",
    "**Recommended:** Run in parallel on different nodes/terminals if hardware allows\n",
    "\n",
    "## Validation\n",
    "\n",
    "After training completes, verify results:\n",
    "\n",
    "```bash\n",
    "# Check checkpoint exists\n",
    "ls -lh novelty_files/checkpoints/ablation/\n",
    "\n",
    "# Load and inspect checkpoint\n",
    "python -c \\\"\n",
    "import torch\n",
    "ckpt = torch.load('novelty_files/checkpoints/ablation/15_FULL_PIPELINE.pt')\n",
    "print(f'Val Accuracy: {ckpt[\\\\\"val_accuracy\\\\\"]:.2f}%')\n",
    "print(f'Epoch: {ckpt[\\\\\"epoch\\\\\"]}')\n",
    "\\\"\n",
    "```\n",
    "\n",
    "## Post-Training Analysis\n",
    "\n",
    "After all configs complete, run Notebook 8 for comprehensive evaluation and visualization.\n",
    "\n",
    "---\n",
    "\n",
    "Generated: {datetime.now().isoformat()}\n",
    "'''\n",
    "\n",
    "readme_path = output_dir / 'README.md'\n",
    "with open(readme_path, 'w') as f:\n",
    "    f.write(readme_content)\n",
    "\n",
    "print(\\\"=\\\"*80)\n",
    "print(\\\"EXECUTION README CREATED\\\")\n",
    "print(\\\"=\\\"*80)\n",
    "print(f\\\"✓ Created: {readme_path}\\\")\n",
    "print(f\\\"\\\\nKey sections:\\\")\n",
    "print(\\\"  • Prerequisites & environment setup\\\")\n",
    "print(\\\"  • Execution commands for each config\\\")\n",
    "print(\\\"  • Monitoring and troubleshooting\\\")\n",
    "print(\\\"  • Expected timelines and accuracies\\\")\n",
    "print(\\\"=\\\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c71c62c",
   "metadata": {},
   "source": [
    "## CELL 7: Create DDP Validation Script\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "416fd28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 7: CREATE DDP VALIDATION SCRIPT\n",
    "# ============================================================\n",
    "\n",
    "validation_script = '''#!/usr/bin/env python3\n",
    "\\\"\\\"\\\"\n",
    "DDP Validation Script\n",
    "\n",
    "Tests that DDP is properly configured before running long training jobs.\n",
    "\n",
    "Usage:\n",
    "    torchrun --nproc_per_node=8 validate_ddp.py\n",
    "\\\"\\\"\\\"\n",
    "\n",
    "import torch\n",
    "import torch.distributed as dist\n",
    "from datetime import datetime\n",
    "\n",
    "def main():\n",
    "    # Initialize DDP\n",
    "    dist.init_process_group(backend=\\\"nccl\\\")\n",
    "    local_rank = int(os.environ.get(\\\"LOCAL_RANK\\\", 0))\n",
    "    world_size = dist.get_world_size()\n",
    "    \n",
    "    torch.cuda.set_device(local_rank)\n",
    "    device = torch.device(f\\\"cuda:{local_rank}\\\")\n",
    "    \n",
    "    if local_rank == 0:\n",
    "        print(\\\"=\\\"*80)\n",
    "        print(\\\"DDP VALIDATION TEST\\\")\n",
    "        print(\\\"=\\\"*80)\n",
    "        print(f\\\"Timestamp: {datetime.now().isoformat()}\\\")\n",
    "        print(f\\\"World Size: {world_size} GPUs\\\")\n",
    "        print(f\\\"Backend: NCCL\\\")\n",
    "    \n",
    "    # Test 1: Basic communication\n",
    "    if local_rank == 0:\n",
    "        print(\\\"\\\\nTest 1: Basic Communication\\\")\n",
    "    \n",
    "    test_tensor = torch.ones(1, device=device) * (local_rank + 1)\n",
    "    dist.all_reduce(test_tensor, op=dist.ReduceOp.SUM)\n",
    "    \n",
    "    expected_sum = sum(range(1, world_size + 1))\n",
    "    if test_tensor.item() == expected_sum:\n",
    "        if local_rank == 0:\n",
    "            print(f\\\"  ✓ All-reduce test passed (sum={test_tensor.item()})\\\")\n",
    "    else:\n",
    "        print(f\\\"  ✗ FAILED on rank {local_rank}: got {test_tensor.item()}, expected {expected_sum}\\\")\n",
    "    \n",
    "    # Test 2: GPU info\n",
    "    if local_rank == 0:\n",
    "        print(f\\\"\\\\nTest 2: GPU Information\\\")\n",
    "        for i in range(world_size):\n",
    "            props = torch.cuda.get_device_properties(i)\n",
    "            print(f\\\"  GPU {i}: {props.name} - {props.total_memory / 1e9:.1f}GB\\\")\n",
    "    \n",
    "    # Test 3: Barrier synchronization\n",
    "    if local_rank == 0:\n",
    "        print(f\\\"\\\\nTest 3: Barrier Synchronization\\\")\n",
    "    \n",
    "    dist.barrier()\n",
    "    \n",
    "    if local_rank == 0:\n",
    "        print(\\\"  ✓ All ranks synchronized successfully\\\")\n",
    "    \n",
    "    # Test 4: Simple model forward pass\n",
    "    if local_rank == 0:\n",
    "        print(f\\\"\\\\nTest 4: Simple Model Forward Pass\\\")\n",
    "    \n",
    "    model = torch.nn.Linear(10, 10).to(device)\n",
    "    model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[local_rank])\n",
    "    \n",
    "    dummy_input = torch.randn(4, 10, device=device)\n",
    "    output = model(dummy_input)\n",
    "    \n",
    "    if local_rank == 0:\n",
    "        print(f\\\"  ✓ DDP model forward pass successful: {output.shape}\\\")\n",
    "    \n",
    "    # Summary\n",
    "    dist.barrier()\n",
    "    if local_rank == 0:\n",
    "        print(\\\"\\\\n\\\" + \\\"=\\\"*80)\n",
    "        print(\\\"✓ ALL DDP VALIDATION TESTS PASSED\\\")\n",
    "        print(\\\"=\\\"*80)\n",
    "        print(\\\"Ready to run DDP training scripts!\\\")\n",
    "        print(\\\"=\\\"*80)\n",
    "    \n",
    "    dist.destroy_process_group()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    import os\n",
    "    main()\n",
    "'''\n",
    "\n",
    "validation_path = output_dir / 'validate_ddp.py'\n",
    "with open(validation_path, 'w') as f:\n",
    "    f.write(validation_script)\n",
    "\n",
    "# Make executable\n",
    "os.chmod(validation_path, 0o755)\n",
    "\n",
    "print(\\\"=\\\"*80)\n",
    "print(\\\"DDP VALIDATION SCRIPT CREATED\\\")\n",
    "print(\\\"=\\\"*80)\n",
    "print(f\\\"✓ Created: {validation_path}\\\")\n",
    "print(f\\\"✓ Made executable\\\")\n",
    "print(f\\\"\\\\nRun before training to verify DDP setup:\\\")\n",
    "print(f\\\"  torchrun --nproc_per_node=8 {validation_path}\\\")\n",
    "print(\\\"=\\\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "893a33d9",
   "metadata": {},
   "source": [
    "## CELL 8: Notebook 9B Completion Summary\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbec0087",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# CELL 8: COMPLETION SUMMARY\n",
    "# ============================================================\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "print(\\\"\\\\n\\\" + \\\"=\\\"*80)\n",
    "print(\\\"NOTEBOOK 9B: DDP EXPORT - COMPLETION SUMMARY\\\")\n",
    "print(\\\"=\\\"*80)\n",
    "\n",
    "# List generated files\n",
    "generated_files = list(output_dir.glob('*.py')) + list(output_dir.glob('*.md'))\n",
    "\n",
    "print(f\\\"\\\\n✓ Generated {len(generated_files)} files in {output_dir}:\\\")\n",
    "for file in sorted(generated_files):\n",
    "    size_kb = file.stat().st_size / 1024\n",
    "    print(f\\\"  • {file.name:30s} ({size_kb:.1f} KB)\\\")\n",
    "\n",
    "print(f\\\"\\\\nConfiguration Scripts:\\\")\n",
    "print(f\\\"  • ablation_ddp_09.py      - Config 09: ViT + Aug + NSL (DDP)\\\")\n",
    "print(f\\\"  • ablation_single_14.py   - Config 14: Full Pipeline (Single GPU)\\\")\n",
    "print(f\\\"  • ablation_ddp_15.py      - Config 15: Full Pipeline (DDP)\\\")\n",
    "\n",
    "print(f\\\"\\\\nUtility Files:\\\")\n",
    "print(f\\\"  • README.md               - Execution guide\\\")\n",
    "print(f\\\"  • validate_ddp.py         - DDP validation test\\\")\n",
    "\n",
    "print(f\\\"\\\\n\\\" + \\\"-\\\"*80)\n",
    "print(\\\"NEXT STEPS\\\")\n",
    "print(\\\"-\\\"*80)\n",
    "print(\\\"✓ Notebook 9B COMPLETE: DDP Scripts Generated\\\")\n",
    "print(\\\"\\\\n1. Validate DDP setup:\\\")\n",
    "print(f\\\"   cd {output_dir.parent}\\\")\n",
    "print(\\\"   torchrun --nproc_per_node=8 ablation_scripts/validate_ddp.py\\\")\n",
    "\n",
    "print(\\\"\\\\n2. Run configurations (in order of complexity):\\\")\n",
    "print(\\\"\\\\n   Config 09 (simpler, faster):\\\")\n",
    "print(\\\"   torchrun --nproc_per_node=8 ablation_scripts/ablation_ddp_09.py\\\")\n",
    "\n",
    "print(\\\"\\\\n   Config 14 (single GPU baseline):\\\")\n",
    "print(\\\"   python ablation_scripts/ablation_single_14.py\\\")\n",
    "\n",
    "print(\\\"\\\\n   Config 15 (final goal - all components):\\\")\n",
    "print(\\\"   torchrun --nproc_per_node=8 --master_port=29501 ablation_scripts/ablation_ddp_15.py\\\")\n",
    "\n",
    "print(\\\"\\\\n3. Monitor execution:\\\")\n",
    "print(\\\"   watch -n 1 nvidia-smi\\\")\n",
    "\n",
    "print(\\\"\\\\n4. After completion, verify results:\\\")\n",
    "print(\\\"   ls -lh novelty_files/checkpoints/ablation/\\\")\n",
    "\n",
    "print(f\\\"\\\\n\\\" + \\\"-\\\"*80)\n",
    "print(\\\"EXPECTED OUTCOMES\\\")\n",
    "print(\\\"-\\\"*80)\n",
    "print(\\\"Config 09:  ~84-86% (ViT + Aug + NSL, DDP)\\\")\n",
    "print(\\\"Config 14:  ~86-88% (Full pipeline, single GPU)\\\")\n",
    "print(\\\"Config 15:  ~87-90% (Full pipeline, DDP) ← TARGET GOAL\\\")\n",
    "\n",
    "print(f\\\"\\\\n\\\" + \\\"=\\\"*80)\n",
    "\n",
    "# Save completion status\n",
    "completion_status = {\n",
    "    'notebook': 'Notebook 9B: DDP Export',\n",
    "    'completed': True,\n",
    "    'timestamp': datetime.now().isoformat(),\n",
    "    'output_directory': str(output_dir),\n",
    "    'generated_files': [str(f.relative_to(output_dir.parent)) for f in generated_files],\n",
    "    'configurations': {\n",
    "        '09': 'ViT + Aug + NSL + DDP',\n",
    "        '14': 'Full Pipeline (Single GPU)',\n",
    "        '15': 'Full Pipeline + DDP'\n",
    "    }\n",
    "}\n",
    "\n",
    "completion_path = Path('./novelty_files/logs/notebook_09b_completion.json')\n",
    "completion_path.parent.mkdir(parents=True, exist_ok=True)\n",
    "with open(completion_path, 'w') as f:\n",
    "    json.dump(completion_status, f, indent=2)\n",
    "\n",
    "print(f\\\"✓ Completion status saved to: {completion_path}\\\")\n",
    "print(\\\"=\\\"*80)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
