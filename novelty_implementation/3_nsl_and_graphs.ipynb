{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8bd7936",
   "metadata": {},
   "source": [
    "## CELL 1: Environment Setup & Load Previous Results\n",
    "\n",
    "Load configuration and ViT model from previous notebooks.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "f65f17a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "NOTEBOOK 3: NEURAL STRUCTURED LEARNING & GRAPH CONSTRUCTION\n",
      "================================================================================\n",
      "PyTorch Version: 2.9.1+cu128\n",
      "CUDA Available: True\n",
      "Device Count: 8\n",
      "Active GPU: NVIDIA H200\n",
      "================================================================================\n",
      "\n",
      "✓ Using device: cuda:0\n",
      "✓ Random seeds set to 42\n",
      "\n",
      "✓ Loaded configuration from novelty_files/configs/notebook_01_config.json\n",
      "✓ Loaded class mappings (8 classes)\n",
      "✓ Loaded splits: 53,097 train, 11,379 val\n",
      "\n",
      "================================================================================\n",
      "INITIALIZATION COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 1: ENVIRONMENT SETUP & IMPORTS\n",
    "# ============================================================\n",
    "\n",
    "\"\"\"\n",
    "This cell:\n",
    "1. Imports all required libraries\n",
    "2. Loads configuration from Notebook 1\n",
    "3. Loads ViT model checkpoint from Notebook 2\n",
    "4. Sets up device and random seeds\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import json\n",
    "import pickle\n",
    "import random\n",
    "from pathlib import Path\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# PyTorch\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "# Vision\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "\n",
    "# Data & ML\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import NearestNeighbors\n",
    "from scipy.sparse import csr_matrix\n",
    "\n",
    "# Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# timm for ViT\n",
    "import timm\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"NOTEBOOK 3: NEURAL STRUCTURED LEARNING & GRAPH CONSTRUCTION\")\n",
    "print(\"=\"*80)\n",
    "print(f\"PyTorch Version: {torch.__version__}\")\n",
    "print(f\"CUDA Available: {torch.cuda.is_available()}\")\n",
    "print(f\"Device Count: {torch.cuda.device_count()}\")\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    print(f\"Active GPU: {torch.cuda.get_device_name(0)}\")\n",
    "\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Set device\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f\"\\n✓ Using device: {device}\")\n",
    "\n",
    "# Set random seeds\n",
    "RANDOM_SEED = 42\n",
    "torch.manual_seed(RANDOM_SEED)\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "if torch.cuda.is_available():\n",
    "    torch.cuda.manual_seed(RANDOM_SEED)\n",
    "\n",
    "print(f\"✓ Random seeds set to {RANDOM_SEED}\")\n",
    "\n",
    "# ============================================================\n",
    "# LOAD CONFIGURATION FROM NOTEBOOK 1\n",
    "# ============================================================\n",
    "\n",
    "base_dir = Path('./novelty_files')\n",
    "config_path = base_dir / 'configs' / 'notebook_01_config.json'\n",
    "\n",
    "if not config_path.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"Configuration file not found: {config_path}\\n\"\n",
    "        f\"Please run Notebook 1 first to create the configuration.\"\n",
    "    )\n",
    "\n",
    "with open(config_path, 'r') as f:\n",
    "    CONFIG = json.load(f)\n",
    "\n",
    "print(f\"\\n✓ Loaded configuration from {config_path}\")\n",
    "\n",
    "# Load class mappings\n",
    "dist_path = base_dir / 'splits' / 'class_distribution.json'\n",
    "with open(dist_path, 'r') as f:\n",
    "    dist_data = json.load(f)\n",
    "\n",
    "class_to_idx = dist_data['class_to_idx']\n",
    "idx_to_class = {int(k): v for k, v in dist_data['idx_to_class'].items()}\n",
    "\n",
    "print(f\"✓ Loaded class mappings ({len(class_to_idx)} classes)\")\n",
    "\n",
    "# Load splits\n",
    "with open(base_dir / 'splits' / 'train_indices.pkl', 'rb') as f:\n",
    "    train_indices = pickle.load(f)\n",
    "with open(base_dir / 'splits' / 'val_indices.pkl', 'rb') as f:\n",
    "    val_indices = pickle.load(f)\n",
    "\n",
    "print(f\"✓ Loaded splits: {len(train_indices):,} train, {len(val_indices):,} val\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"INITIALIZATION COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7253ded4",
   "metadata": {},
   "source": [
    "## CELL 2: Reload Dataset & ViT Model\n",
    "\n",
    "Reload the dataset and ViT-Base model checkpoint.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "20e0938c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "RELOADING DATASET & MODEL\n",
      "================================================================================\n",
      "✓ Reloaded 75,855 samples\n",
      "\n",
      "Loading ViT model from: novelty_files/checkpoints/vit_baseline.pt\n",
      "✓ Loaded ViT checkpoint (val_acc=97.39%)\n",
      "✓ Model moved to cuda:0 and set to eval mode\n",
      "✓ Model parameters: 85.8M\n",
      "\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 2: RELOAD DATASET & VIT MODEL\n",
    "# ============================================================\n",
    "\n",
    "\"\"\"\n",
    "This cell:\n",
    "1. Reloads the HMDB51 Fight dataset samples\n",
    "2. Loads the ViT-Base model from Notebook 2 checkpoint\n",
    "3. Prepares model for feature extraction\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RELOADING DATASET & MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================\n",
    "# RELOAD DATASET SAMPLES\n",
    "# ============================================================\n",
    "\n",
    "class HMDB51FightDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Simple dataset for loading HMDB51 Fight images.\n",
    "    \"\"\"\n",
    "    def __init__(self, root_dir: str, split: str, class_to_idx: Dict[str, int]):\n",
    "        self.root_dir = Path(root_dir)\n",
    "        self.split = split\n",
    "        self.class_to_idx = class_to_idx\n",
    "        self.samples = []\n",
    "        \n",
    "        split_dir = self.root_dir / split\n",
    "        for class_name, class_idx in class_to_idx.items():\n",
    "            class_dir = split_dir / class_name\n",
    "            if class_dir.exists():\n",
    "                image_files = list(class_dir.glob('*.jpg')) + list(class_dir.glob('*.png'))\n",
    "                for img_path in image_files:\n",
    "                    self.samples.append({\n",
    "                        'path': str(img_path),\n",
    "                        'label': class_idx,\n",
    "                        'class_name': class_name\n",
    "                    })\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.samples)\n",
    "\n",
    "# Load dataset\n",
    "dataset_path = CONFIG['dataset_path']\n",
    "train_dataset_loader = HMDB51FightDataset(dataset_path, 'train', class_to_idx)\n",
    "test_dataset_loader = HMDB51FightDataset(dataset_path, 'test', class_to_idx)\n",
    "\n",
    "all_samples = train_dataset_loader.samples + test_dataset_loader.samples\n",
    "\n",
    "print(f\"✓ Reloaded {len(all_samples):,} samples\")\n",
    "\n",
    "# ============================================================\n",
    "# LOAD VIT MODEL FROM NOTEBOOK 2 CHECKPOINT\n",
    "# ============================================================\n",
    "\n",
    "vit_checkpoint_path = base_dir / 'checkpoints' / 'vit_baseline.pt'\n",
    "\n",
    "if not vit_checkpoint_path.exists():\n",
    "    raise FileNotFoundError(\n",
    "        f\"ViT checkpoint not found: {vit_checkpoint_path}\\n\"\n",
    "        f\"Please run Notebook 2 first to train the ViT baseline.\"\n",
    "    )\n",
    "\n",
    "print(f\"\\nLoading ViT model from: {vit_checkpoint_path}\")\n",
    "\n",
    "# Create ViT-Base model\n",
    "model = timm.create_model('vit_base_patch16_224', pretrained=False, num_classes=8)\n",
    "\n",
    "# Load checkpoint\n",
    "checkpoint = torch.load(vit_checkpoint_path, map_location='cpu')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "val_acc = checkpoint['val_accuracy']\n",
    "print(f\"✓ Loaded ViT checkpoint (val_acc={val_acc:.2f}%)\")\n",
    "\n",
    "# Move to device\n",
    "model = model.to(device)\n",
    "model.eval()  # Set to evaluation mode\n",
    "\n",
    "print(f\"✓ Model moved to {device} and set to eval mode\")\n",
    "\n",
    "# Count parameters\n",
    "total_params = sum(p.numel() for p in model.parameters())\n",
    "print(f\"✓ Model parameters: {total_params/1e6:.1f}M\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfa30d1d",
   "metadata": {},
   "source": [
    "## CELL 3: Extract Features from ViT Backbone (RESUME-SAFE)\n",
    "\n",
    "Extract feature embeddings from the ViT backbone (before classification head).  \n",
    "**CRITICAL**: Checks if features already exist before extracting.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d010b3f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FEATURE EXTRACTION FROM VIT BACKBONE\n",
      "================================================================================\n",
      "No existing features found. Extracting features...\n",
      "This will take approximately 10-15 minutes.\n",
      "✓ Feature extractor created\n",
      "✓ Created dataloaders (batch_size=128)\n",
      "\n",
      "Extracting train features (53,097 samples)...\n",
      "  Processed 12,800 / 53,097 samples\n",
      "  Processed 25,600 / 53,097 samples\n",
      "  Processed 38,400 / 53,097 samples\n",
      "  Processed 51,200 / 53,097 samples\n",
      "✓ Train features extracted: torch.Size([53097, 768])\n",
      "\n",
      "Extracting val features (11,379 samples)...\n",
      "  Processed 6,400 / 11,379 samples\n",
      "✓ Val features extracted: torch.Size([11379, 768])\n",
      "\n",
      "Saving features...\n",
      "✓ Saved train features to: novelty_files/features/train_features.pt\n",
      "✓ Saved val features to: novelty_files/features/val_features.pt\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "FEATURE STATISTICS\n",
      "--------------------------------------------------------------------------------\n",
      "Train features shape: torch.Size([53097, 768])\n",
      "Val features shape:   torch.Size([11379, 768])\n",
      "Feature dimension:    768 (ViT-Base embedding)\n",
      "\n",
      "Train features statistics:\n",
      "  Mean: -0.0367\n",
      "  Std:  2.2193\n",
      "  Min:  -35.4310\n",
      "  Max:  31.4969\n",
      "\n",
      "================================================================================\n",
      "✓ FEATURE EXTRACTION COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 3: EXTRACT FEATURES (RESUME-SAFE)\n",
    "# ============================================================\n",
    "\n",
    "\"\"\"\n",
    "This cell extracts feature embeddings from the ViT backbone.\n",
    "\n",
    "Feature extraction:\n",
    "- Takes images as input\n",
    "- Passes through ViT patch embedding + transformer blocks\n",
    "- Extracts [CLS] token representation (768-dim for ViT-Base)\n",
    "- Saves features to disk for graph construction\n",
    "\n",
    "RESUME-SAFE: Checks if features already exist before extraction.\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEATURE EXTRACTION FROM VIT BACKBONE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================\n",
    "# CHECK IF FEATURES ALREADY EXIST\n",
    "# ============================================================\n",
    "\n",
    "features_dir = base_dir / 'features'\n",
    "train_features_path = features_dir / 'train_features.pt'\n",
    "val_features_path = features_dir / 'val_features.pt'\n",
    "\n",
    "if train_features_path.exists() and val_features_path.exists():\n",
    "    print(\"✓ Found existing feature files, loading instead of extracting...\")\n",
    "    \n",
    "    train_features = torch.load(train_features_path)\n",
    "    val_features = torch.load(val_features_path)\n",
    "    \n",
    "    print(f\"✓ Loaded train features: {train_features.shape}\")\n",
    "    print(f\"✓ Loaded val features: {val_features.shape}\")\n",
    "    \n",
    "else:\n",
    "    print(\"No existing features found. Extracting features...\")\n",
    "    print(\"This will take approximately 10-15 minutes.\")\n",
    "    \n",
    "    # ============================================================\n",
    "    # DEFINE FEATURE EXTRACTOR\n",
    "    # ============================================================\n",
    "    \n",
    "    class FeatureExtractor(nn.Module):\n",
    "        \"\"\"\n",
    "        Wrapper to extract features from ViT backbone.\n",
    "        \n",
    "        Returns the [CLS] token representation (before classification head).\n",
    "        For ViT-Base, this is a 768-dimensional vector.\n",
    "        \"\"\"\n",
    "        def __init__(self, vit_model):\n",
    "            super().__init__()\n",
    "            self.vit = vit_model\n",
    "        \n",
    "        def forward(self, x):\n",
    "            # Forward through patch embedding and transformer\n",
    "            x = self.vit.patch_embed(x)\n",
    "            x = self.vit._pos_embed(x)\n",
    "            x = self.vit.blocks(x)\n",
    "            x = self.vit.norm(x)\n",
    "            \n",
    "            # Extract [CLS] token (first token)\n",
    "            cls_token = x[:, 0]\n",
    "            \n",
    "            return cls_token\n",
    "    \n",
    "    feature_extractor = FeatureExtractor(model).to(device)\n",
    "    feature_extractor.eval()\n",
    "    \n",
    "    print(\"✓ Feature extractor created\")\n",
    "    \n",
    "    # ============================================================\n",
    "    # CREATE DATASET FOR FEATURE EXTRACTION\n",
    "    # ============================================================\n",
    "    \n",
    "    class HMDB51Dataset(Dataset):\n",
    "        def __init__(self, samples, indices, transform=None):\n",
    "            self.samples = [samples[i] for i in indices]\n",
    "            self.transform = transform\n",
    "        \n",
    "        def __len__(self):\n",
    "            return len(self.samples)\n",
    "        \n",
    "        def __getitem__(self, idx):\n",
    "            sample = self.samples[idx]\n",
    "            img = Image.open(sample['path']).convert('RGB')\n",
    "            \n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "            \n",
    "            return img, sample['label']\n",
    "    \n",
    "    # Define transform (same as validation)\n",
    "    vit_mean = [0.485, 0.456, 0.406]\n",
    "    vit_std = [0.229, 0.224, 0.225]\n",
    "    \n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((224, 224)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=vit_mean, std=vit_std),\n",
    "    ])\n",
    "    \n",
    "    # Create datasets\n",
    "    train_dataset = HMDB51Dataset(all_samples, train_indices, transform=transform)\n",
    "    val_dataset = HMDB51Dataset(all_samples, val_indices, transform=transform)\n",
    "    \n",
    "    # Create dataloaders\n",
    "    batch_size = 128  # Larger batch for feature extraction\n",
    "    \n",
    "    train_loader = DataLoader(\n",
    "        train_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,  # Keep order for indexing\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    val_loader = DataLoader(\n",
    "        val_dataset,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=False,\n",
    "        num_workers=4,\n",
    "        pin_memory=True\n",
    "    )\n",
    "    \n",
    "    print(f\"✓ Created dataloaders (batch_size={batch_size})\")\n",
    "    \n",
    "    # ============================================================\n",
    "    # EXTRACT TRAIN FEATURES\n",
    "    # ============================================================\n",
    "    \n",
    "    print(f\"\\nExtracting train features ({len(train_dataset):,} samples)...\")\n",
    "    \n",
    "    train_features_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, _) in enumerate(train_loader):\n",
    "            images = images.to(device)\n",
    "            features = feature_extractor(images)\n",
    "            train_features_list.append(features.cpu())\n",
    "            \n",
    "            if (batch_idx + 1) % 100 == 0:\n",
    "                print(f\"  Processed {(batch_idx + 1) * batch_size:,} / {len(train_dataset):,} samples\")\n",
    "    \n",
    "    train_features = torch.cat(train_features_list, dim=0)\n",
    "    print(f\"✓ Train features extracted: {train_features.shape}\")\n",
    "    \n",
    "    # ============================================================\n",
    "    # EXTRACT VAL FEATURES\n",
    "    # ============================================================\n",
    "    \n",
    "    print(f\"\\nExtracting val features ({len(val_dataset):,} samples)...\")\n",
    "    \n",
    "    val_features_list = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (images, _) in enumerate(val_loader):\n",
    "            images = images.to(device)\n",
    "            features = feature_extractor(images)\n",
    "            val_features_list.append(features.cpu())\n",
    "            \n",
    "            if (batch_idx + 1) % 50 == 0:\n",
    "                print(f\"  Processed {(batch_idx + 1) * batch_size:,} / {len(val_dataset):,} samples\")\n",
    "    \n",
    "    val_features = torch.cat(val_features_list, dim=0)\n",
    "    print(f\"✓ Val features extracted: {val_features.shape}\")\n",
    "    \n",
    "    # ============================================================\n",
    "    # SAVE FEATURES\n",
    "    # ============================================================\n",
    "    \n",
    "    print(f\"\\nSaving features...\")\n",
    "    \n",
    "    torch.save(train_features, train_features_path)\n",
    "    print(f\"✓ Saved train features to: {train_features_path}\")\n",
    "    \n",
    "    torch.save(val_features, val_features_path)\n",
    "    print(f\"✓ Saved val features to: {val_features_path}\")\n",
    "\n",
    "# ============================================================\n",
    "# VERIFY FEATURE SHAPES\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"FEATURE STATISTICS\")\n",
    "print(\"-\"*80)\n",
    "print(f\"Train features shape: {train_features.shape}\")\n",
    "print(f\"Val features shape:   {val_features.shape}\")\n",
    "print(f\"Feature dimension:    {train_features.shape[1]} (ViT-Base embedding)\")\n",
    "\n",
    "# Check feature statistics\n",
    "print(f\"\\nTrain features statistics:\")\n",
    "print(f\"  Mean: {train_features.mean():.4f}\")\n",
    "print(f\"  Std:  {train_features.std():.4f}\")\n",
    "print(f\"  Min:  {train_features.min():.4f}\")\n",
    "print(f\"  Max:  {train_features.max():.4f}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✓ FEATURE EXTRACTION COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf8e59f1",
   "metadata": {},
   "source": [
    "## CELL 4: Build k-NN Graph (RESUME-SAFE)\n",
    "\n",
    "Construct k-nearest neighbors graph for Neural Structured Learning.  \n",
    "**k=5** neighbors per sample.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1cf34dca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "K-NN GRAPH CONSTRUCTION\n",
      "================================================================================\n",
      "No existing graph found. Constructing k-NN graph...\n",
      "This will take approximately 5-10 minutes.\n",
      "\n",
      "Graph parameters:\n",
      "  k (neighbors per node): 5\n",
      "  Number of nodes: 53,097\n",
      "\n",
      "Fitting k-NN model on train features...\n",
      "✓ k-NN model fitted\n",
      "\n",
      "Finding 5 nearest neighbors for each sample...\n",
      "✓ Neighbors found\n",
      "  Neighbors shape: (53097, 5)\n",
      "  Distances shape: (53097, 5)\n",
      "\n",
      "Creating edge list...\n",
      "✓ Edge list created\n",
      "  Number of edges: 265,485\n",
      "  Average degree: 5.0\n",
      "\n",
      "Saving graph data...\n",
      "✓ Saved graph data to: novelty_files/graphs/train_knn_graph.pkl\n",
      "✓ Saved neighbor indices to: novelty_files/graphs/train_neighbors.npy\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "GRAPH STATISTICS\n",
      "--------------------------------------------------------------------------------\n",
      "Total nodes:  53,097\n",
      "Total edges:  265,485\n",
      "k neighbors:  5\n",
      "Metric:       cosine\n",
      "\n",
      "Sample neighbors (first 5 nodes):\n",
      "  Node 0: neighbors = [8124, 18642, 51242, 23757, 42690]\n",
      "  Node 1: neighbors = [10145, 13396, 18124, 46312, 43583]\n",
      "  Node 2: neighbors = [30809, 11360, 14661, 12697, 28224]\n",
      "  Node 3: neighbors = [44955, 46175, 43845, 43832, 37623]\n",
      "  Node 4: neighbors = [5741, 3078, 42875, 5756, 9687]\n",
      "\n",
      "================================================================================\n",
      "✓ GRAPH CONSTRUCTION COMPLETE\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 4: BUILD K-NN GRAPH (RESUME-SAFE)\n",
    "# ============================================================\n",
    "\n",
    "\"\"\"\n",
    "This cell constructs a k-nearest neighbors graph for NSL regularization.\n",
    "\n",
    "Graph construction:\n",
    "- For each training sample, find k=5 nearest neighbors in feature space\n",
    "- Create edge list connecting each node to its neighbors\n",
    "- Save graph structure for use in training\n",
    "\n",
    "RESUME-SAFE: Checks if graph already exists before construction.\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"K-NN GRAPH CONSTRUCTION\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================\n",
    "# CHECK IF GRAPH ALREADY EXISTS\n",
    "# ============================================================\n",
    "\n",
    "graphs_dir = base_dir / 'graphs'\n",
    "graph_path = graphs_dir / 'train_knn_graph.pkl'\n",
    "neighbors_path = graphs_dir / 'train_neighbors.npy'\n",
    "\n",
    "if graph_path.exists() and neighbors_path.exists():\n",
    "    print(\"✓ Found existing graph files, loading instead of constructing...\")\n",
    "    \n",
    "    with open(graph_path, 'rb') as f:\n",
    "        graph_data = pickle.load(f)\n",
    "    \n",
    "    neighbors_indices = np.load(neighbors_path)\n",
    "    \n",
    "    print(f\"✓ Loaded graph data:\")\n",
    "    print(f\"  Num nodes: {graph_data['num_nodes']}\")\n",
    "    print(f\"  Num edges: {graph_data['num_edges']}\")\n",
    "    print(f\"  k neighbors: {graph_data['k']}\")\n",
    "    print(f\"  Neighbors shape: {neighbors_indices.shape}\")\n",
    "    \n",
    "else:\n",
    "    print(\"No existing graph found. Constructing k-NN graph...\")\n",
    "    print(\"This will take approximately 5-10 minutes.\")\n",
    "    \n",
    "    # ============================================================\n",
    "    # GRAPH CONSTRUCTION PARAMETERS\n",
    "    # ============================================================\n",
    "    \n",
    "    k = 5  # Number of nearest neighbors\n",
    "    print(f\"\\nGraph parameters:\")\n",
    "    print(f\"  k (neighbors per node): {k}\")\n",
    "    print(f\"  Number of nodes: {len(train_features):,}\")\n",
    "    \n",
    "    # ============================================================\n",
    "    # BUILD K-NN GRAPH USING SKLEARN\n",
    "    # ============================================================\n",
    "    \n",
    "    print(f\"\\nFitting k-NN model on train features...\")\n",
    "    \n",
    "    # Use cosine similarity for feature space\n",
    "    # (L2 normalized features work well with cosine distance)\n",
    "    nbrs = NearestNeighbors(\n",
    "        n_neighbors=k+1,  # +1 because first neighbor is the point itself\n",
    "        algorithm='auto',\n",
    "        metric='cosine',\n",
    "        n_jobs=-1  # Use all CPU cores\n",
    "    )\n",
    "    \n",
    "    # Fit on training features\n",
    "    nbrs.fit(train_features.numpy())\n",
    "    \n",
    "    print(f\"✓ k-NN model fitted\")\n",
    "    \n",
    "    # ============================================================\n",
    "    # FIND NEIGHBORS FOR ALL TRAINING SAMPLES\n",
    "    # ============================================================\n",
    "    \n",
    "    print(f\"\\nFinding {k} nearest neighbors for each sample...\")\n",
    "    \n",
    "    distances, indices = nbrs.kneighbors(train_features.numpy())\n",
    "    \n",
    "    # Remove self (first column is always the point itself with distance 0)\n",
    "    neighbors_indices = indices[:, 1:]  # Shape: (num_samples, k)\n",
    "    neighbors_distances = distances[:, 1:]  # Shape: (num_samples, k)\n",
    "    \n",
    "    print(f\"✓ Neighbors found\")\n",
    "    print(f\"  Neighbors shape: {neighbors_indices.shape}\")\n",
    "    print(f\"  Distances shape: {neighbors_distances.shape}\")\n",
    "    \n",
    "    # ============================================================\n",
    "    # CREATE EDGE LIST\n",
    "    # ============================================================\n",
    "    \n",
    "    print(f\"\\nCreating edge list...\")\n",
    "    \n",
    "    num_nodes = len(train_features)\n",
    "    edge_list = []\n",
    "    \n",
    "    for i in range(num_nodes):\n",
    "        for j in range(k):\n",
    "            neighbor_idx = neighbors_indices[i, j]\n",
    "            distance = neighbors_distances[i, j]\n",
    "            edge_list.append((i, neighbor_idx, distance))\n",
    "    \n",
    "    num_edges = len(edge_list)\n",
    "    \n",
    "    print(f\"✓ Edge list created\")\n",
    "    print(f\"  Number of edges: {num_edges:,}\")\n",
    "    print(f\"  Average degree: {num_edges / num_nodes:.1f}\")\n",
    "    \n",
    "    # ============================================================\n",
    "    # SAVE GRAPH DATA\n",
    "    # ============================================================\n",
    "    \n",
    "    print(f\"\\nSaving graph data...\")\n",
    "    \n",
    "    graph_data = {\n",
    "        'num_nodes': num_nodes,\n",
    "        'num_edges': num_edges,\n",
    "        'k': k,\n",
    "        'edge_list': edge_list,\n",
    "        'metric': 'cosine',\n",
    "    }\n",
    "    \n",
    "    with open(graph_path, 'wb') as f:\n",
    "        pickle.dump(graph_data, f)\n",
    "    print(f\"✓ Saved graph data to: {graph_path}\")\n",
    "    \n",
    "    np.save(neighbors_path, neighbors_indices)\n",
    "    print(f\"✓ Saved neighbor indices to: {neighbors_path}\")\n",
    "\n",
    "# ============================================================\n",
    "# VERIFY GRAPH STRUCTURE\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"GRAPH STATISTICS\")\n",
    "print(\"-\"*80)\n",
    "print(f\"Total nodes:  {graph_data['num_nodes']:,}\")\n",
    "print(f\"Total edges:  {graph_data['num_edges']:,}\")\n",
    "print(f\"k neighbors:  {graph_data['k']}\")\n",
    "print(f\"Metric:       {graph_data['metric']}\")\n",
    "\n",
    "# Sample a few nodes and show their neighbors\n",
    "print(f\"\\nSample neighbors (first 5 nodes):\")\n",
    "for i in range(min(5, len(neighbors_indices))):\n",
    "    print(f\"  Node {i}: neighbors = {neighbors_indices[i].tolist()}\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✓ GRAPH CONSTRUCTION COMPLETE\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "514d2499",
   "metadata": {},
   "source": [
    "## CELL 5: Implement NSL Loss Functions\n",
    "\n",
    "Implement Virtual Adversarial Training (VAT) and L2 Neighbor Regularization losses.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "2945de94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "NSL LOSS FUNCTIONS\n",
      "================================================================================\n",
      "✓ NSL loss functions defined:\n",
      "  • virtual_adversarial_loss() - VAT regularization\n",
      "  • l2_neighbor_loss() - Neighbor consistency\n",
      "  • nsl_loss() - Combined NSL loss\n",
      "\n",
      "================================================================================\n",
      "✓ NSL COMPONENTS READY\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 5: NSL LOSS FUNCTIONS\n",
    "# ============================================================\n",
    "\n",
    "\"\"\"\n",
    "This cell implements the Neural Structured Learning loss components:\n",
    "\n",
    "1. Virtual Adversarial Training (VAT) Loss:\n",
    "   - Adds small adversarial perturbations to inputs\n",
    "   - Encourages smooth predictions under perturbations\n",
    "   \n",
    "2. L2 Neighbor Regularization:\n",
    "   - Encourages similar predictions for k-NN neighbors\n",
    "   - Uses graph structure from Cell 4\n",
    "\n",
    "3. Combined NSL Loss:\n",
    "   - Total loss = CE_loss + λ_vat * VAT_loss + λ_neighbor * L2_loss\n",
    "\"\"\"\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"NSL LOSS FUNCTIONS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# ============================================================\n",
    "# VIRTUAL ADVERSARIAL TRAINING (VAT) LOSS\n",
    "# ============================================================\n",
    "\n",
    "def virtual_adversarial_loss(model, x, eps=8.0/255.0, xi=1e-6, num_iters=1):\n",
    "    \"\"\"\n",
    "    Compute Virtual Adversarial Training (VAT) loss.\n",
    "    \n",
    "    VAT encourages the model to produce consistent predictions\n",
    "    when small adversarial perturbations are added to the input.\n",
    "    \n",
    "    Args:\n",
    "        model: Neural network model\n",
    "        x: Input images (batch_size, 3, 224, 224)\n",
    "        eps: Perturbation magnitude (default: 8/255 for image inputs)\n",
    "        xi: Small constant for numerical stability\n",
    "        num_iters: Number of power iterations for adversarial direction\n",
    "    \n",
    "    Returns:\n",
    "        vat_loss: VAT regularization loss (scalar)\n",
    "    \"\"\"\n",
    "    # Get prediction for original input\n",
    "    with torch.no_grad():\n",
    "        pred_orig = F.softmax(model(x), dim=1)\n",
    "    \n",
    "    # Generate random perturbation direction\n",
    "    d = torch.randn_like(x)\n",
    "    d = d / (torch.norm(d, p=2, dim=(1,2,3), keepdim=True) + xi)\n",
    "    \n",
    "    # Power iteration to find adversarial direction\n",
    "    for _ in range(num_iters):\n",
    "        d.requires_grad_(True)\n",
    "        pred_perturbed = F.softmax(model(x + xi * d), dim=1)\n",
    "        \n",
    "        # KL divergence between original and perturbed predictions\n",
    "        kl_div = F.kl_div(\n",
    "            pred_perturbed.log(),\n",
    "            pred_orig,\n",
    "            reduction='batchmean'\n",
    "        )\n",
    "        \n",
    "        # Compute gradient of KL w.r.t. perturbation\n",
    "        grad = torch.autograd.grad(kl_div, d)[0]\n",
    "        d = grad / (torch.norm(grad, p=2, dim=(1,2,3), keepdim=True) + xi)\n",
    "        d = d.detach()\n",
    "    \n",
    "    # Compute final VAT loss with scaled perturbation\n",
    "    d = eps * d\n",
    "    pred_adv = F.softmax(model(x + d), dim=1)\n",
    "    \n",
    "    vat_loss = F.kl_div(\n",
    "        pred_adv.log(),\n",
    "        pred_orig,\n",
    "        reduction='batchmean'\n",
    "    )\n",
    "    \n",
    "    return vat_loss\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# L2 NEIGHBOR REGULARIZATION LOSS\n",
    "# ============================================================\n",
    "\n",
    "def l2_neighbor_loss(model, x, neighbor_x, temperature=1.0):\n",
    "    \"\"\"\n",
    "    Compute L2 neighbor regularization loss.\n",
    "    \n",
    "    Encourages the model to produce similar predictions for\n",
    "    samples that are neighbors in the k-NN graph.\n",
    "    \n",
    "    Args:\n",
    "        model: Neural network model\n",
    "        x: Input images (batch_size, 3, 224, 224)\n",
    "        neighbor_x: Neighbor images (batch_size, 3, 224, 224)\n",
    "        temperature: Softmax temperature for predictions\n",
    "    \n",
    "    Returns:\n",
    "        neighbor_loss: L2 distance between predictions (scalar)\n",
    "    \"\"\"\n",
    "    # Get predictions for original samples\n",
    "    pred = F.softmax(model(x) / temperature, dim=1)\n",
    "    \n",
    "    # Get predictions for neighbor samples\n",
    "    pred_neighbor = F.softmax(model(neighbor_x) / temperature, dim=1)\n",
    "    \n",
    "    # Compute L2 distance between prediction distributions\n",
    "    neighbor_loss = F.mse_loss(pred, pred_neighbor, reduction='mean')\n",
    "    \n",
    "    return neighbor_loss\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# COMBINED NSL LOSS\n",
    "# ============================================================\n",
    "\n",
    "def nsl_loss(model, x, labels, neighbor_x=None, \n",
    "             lambda_ce=1.0, lambda_vat=0.1, lambda_neighbor=0.1):\n",
    "    \"\"\"\n",
    "    Compute combined Neural Structured Learning loss.\n",
    "    \n",
    "    Total loss = λ_ce * CE_loss + λ_vat * VAT_loss + λ_neighbor * L2_loss\n",
    "    \n",
    "    Args:\n",
    "        model: Neural network model\n",
    "        x: Input images\n",
    "        labels: Ground truth labels\n",
    "        neighbor_x: Neighbor images (optional, for L2 regularization)\n",
    "        lambda_ce: Weight for classification loss\n",
    "        lambda_vat: Weight for VAT loss\n",
    "        lambda_neighbor: Weight for neighbor regularization\n",
    "    \n",
    "    Returns:\n",
    "        total_loss: Combined NSL loss\n",
    "        loss_dict: Dictionary with individual loss components\n",
    "    \"\"\"\n",
    "    # Classification loss (standard cross-entropy)\n",
    "    outputs = model(x)\n",
    "    ce_loss = F.cross_entropy(outputs, labels)\n",
    "    \n",
    "    # Virtual adversarial loss\n",
    "    vat_loss_val = virtual_adversarial_loss(model, x)\n",
    "    \n",
    "    # Neighbor regularization loss (if neighbors provided)\n",
    "    if neighbor_x is not None:\n",
    "        neighbor_loss_val = l2_neighbor_loss(model, x, neighbor_x)\n",
    "    else:\n",
    "        neighbor_loss_val = torch.tensor(0.0, device=x.device)\n",
    "    \n",
    "    # Combined loss\n",
    "    total_loss = (\n",
    "        lambda_ce * ce_loss +\n",
    "        lambda_vat * vat_loss_val +\n",
    "        lambda_neighbor * neighbor_loss_val\n",
    "    )\n",
    "    \n",
    "    loss_dict = {\n",
    "        'total': total_loss.item(),\n",
    "        'ce': ce_loss.item(),\n",
    "        'vat': vat_loss_val.item(),\n",
    "        'neighbor': neighbor_loss_val.item() if neighbor_x is not None else 0.0\n",
    "    }\n",
    "    \n",
    "    return total_loss, loss_dict\n",
    "\n",
    "\n",
    "print(\"✓ NSL loss functions defined:\")\n",
    "print(\"  • virtual_adversarial_loss() - VAT regularization\")\n",
    "print(\"  • l2_neighbor_loss() - Neighbor consistency\")\n",
    "print(\"  • nsl_loss() - Combined NSL loss\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"✓ NSL COMPONENTS READY\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0262e59b",
   "metadata": {},
   "source": [
    "## CELL 6: Notebook 3 Summary & Completion\n",
    "\n",
    "Summary of NSL components and next steps.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d433b3d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "NOTEBOOK 3: NSL & GRAPHS - COMPLETION SUMMARY\n",
      "================================================================================\n",
      "\n",
      "Verifying required files:\n",
      "  ✓ Train Features: novelty_files/features/train_features.pt\n",
      "  ✓ Val Features: novelty_files/features/val_features.pt\n",
      "  ✓ k-NN Graph: novelty_files/graphs/train_knn_graph.pkl\n",
      "  ✓ Neighbor Indices: novelty_files/graphs/train_neighbors.npy\n",
      "\n",
      "✓ All required files successfully created!\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "NSL COMPONENTS SUMMARY\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "✓ Feature Extraction:\n",
      "  • Train features: torch.Size([53097, 768])\n",
      "  • Val features: torch.Size([11379, 768])\n",
      "  • Feature dimension: 768 (ViT-Base)\n",
      "\n",
      "✓ Graph Construction:\n",
      "  • Nodes: 53,097 (training samples)\n",
      "  • Edges: 265,485\n",
      "  • k-NN: 5 neighbors per node\n",
      "  • Metric: cosine\n",
      "\n",
      "✓ NSL Loss Functions:\n",
      "  • virtual_adversarial_loss() - Implemented\n",
      "  • l2_neighbor_loss() - Implemented\n",
      "  • nsl_loss() - Combined loss function\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "EXPECTED IMPACT\n",
      "--------------------------------------------------------------------------------\n",
      "NSL regularization typically provides:\n",
      "  • +2-3% accuracy improvement\n",
      "  • Better generalization on unseen data\n",
      "  • More robust predictions\n",
      "  • Smoother decision boundaries\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "NEXT STEPS\n",
      "--------------------------------------------------------------------------------\n",
      "✓ Notebook 3 COMPLETE: NSL & Graph Construction\n",
      "\n",
      "NSL components are ready for use in Notebook 4 training!\n",
      "\n",
      "Note: Notebook 4 (DDP Training) is already running.\n",
      "      These NSL components will be used in Notebook 6\n",
      "      for adversarial fine-tuning.\n",
      "\n",
      "================================================================================\n",
      "NOTEBOOK 3: ✓ SUCCESSFULLY COMPLETED\n",
      "================================================================================\n",
      "\n",
      "✓ Completion status saved to: novelty_files/logs/notebook_03_completion.json\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# CELL 6: NOTEBOOK 3 COMPLETION SUMMARY\n",
    "# ============================================================\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"NOTEBOOK 3: NSL & GRAPHS - COMPLETION SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Verify all required files exist\n",
    "required_files = {\n",
    "    'Train Features': base_dir / 'features' / 'train_features.pt',\n",
    "    'Val Features': base_dir / 'features' / 'val_features.pt',\n",
    "    'k-NN Graph': base_dir / 'graphs' / 'train_knn_graph.pkl',\n",
    "    'Neighbor Indices': base_dir / 'graphs' / 'train_neighbors.npy',\n",
    "}\n",
    "\n",
    "print(\"\\nVerifying required files:\")\n",
    "all_files_exist = True\n",
    "\n",
    "for file_desc, file_path in required_files.items():\n",
    "    exists = file_path.exists()\n",
    "    status = \"✓\" if exists else \"✗\"\n",
    "    print(f\"  {status} {file_desc}: {file_path}\")\n",
    "    if not exists:\n",
    "        all_files_exist = False\n",
    "\n",
    "if all_files_exist:\n",
    "    print(\"\\n✓ All required files successfully created!\")\n",
    "else:\n",
    "    print(\"\\n✗ ERROR: Some required files are missing!\")\n",
    "\n",
    "# Summary of outputs\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"NSL COMPONENTS SUMMARY\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "print(f\"\\n✓ Feature Extraction:\")\n",
    "print(f\"  • Train features: {train_features.shape}\")\n",
    "print(f\"  • Val features: {val_features.shape}\")\n",
    "print(f\"  • Feature dimension: {train_features.shape[1]} (ViT-Base)\")\n",
    "\n",
    "print(f\"\\n✓ Graph Construction:\")\n",
    "print(f\"  • Nodes: {graph_data['num_nodes']:,} (training samples)\")\n",
    "print(f\"  • Edges: {graph_data['num_edges']:,}\")\n",
    "print(f\"  • k-NN: {graph_data['k']} neighbors per node\")\n",
    "print(f\"  • Metric: {graph_data['metric']}\")\n",
    "\n",
    "print(f\"\\n✓ NSL Loss Functions:\")\n",
    "print(f\"  • virtual_adversarial_loss() - Implemented\")\n",
    "print(f\"  • l2_neighbor_loss() - Implemented\")\n",
    "print(f\"  • nsl_loss() - Combined loss function\")\n",
    "\n",
    "# Expected impact\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"EXPECTED IMPACT\")\n",
    "print(\"-\"*80)\n",
    "print(\"NSL regularization typically provides:\")\n",
    "print(\"  • +2-3% accuracy improvement\")\n",
    "print(\"  • Better generalization on unseen data\")\n",
    "print(\"  • More robust predictions\")\n",
    "print(\"  • Smoother decision boundaries\")\n",
    "\n",
    "# Next steps\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"NEXT STEPS\")\n",
    "print(\"-\"*80)\n",
    "print(\"✓ Notebook 3 COMPLETE: NSL & Graph Construction\")\n",
    "print(\"\\nNSL components are ready for use in Notebook 4 training!\")\n",
    "print(\"\\nNote: Notebook 4 (DDP Training) is already running.\")\n",
    "print(\"      These NSL components will be used in Notebook 6\")\n",
    "print(\"      for adversarial fine-tuning.\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"NOTEBOOK 3: ✓ SUCCESSFULLY COMPLETED\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Save completion status\n",
    "completion_status = {\n",
    "    'notebook': 'Notebook 3: NSL & Graphs',\n",
    "    'completed': True,\n",
    "    'timestamp': pd.Timestamp.now().isoformat(),\n",
    "    'outputs': {\n",
    "        'train_features_shape': list(train_features.shape),\n",
    "        'val_features_shape': list(val_features.shape),\n",
    "        'graph_nodes': int(graph_data['num_nodes']),\n",
    "        'graph_edges': int(graph_data['num_edges']),\n",
    "        'k_neighbors': graph_data['k'],\n",
    "    },\n",
    "    'nsl_functions': [\n",
    "        'virtual_adversarial_loss',\n",
    "        'l2_neighbor_loss',\n",
    "        'nsl_loss'\n",
    "    ]\n",
    "}\n",
    "\n",
    "completion_path = base_dir / 'logs' / 'notebook_03_completion.json'\n",
    "with open(completion_path, 'w') as f:\n",
    "    json.dump(completion_status, f, indent=2)\n",
    "\n",
    "print(f\"\\n✓ Completion status saved to: {completion_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "major project",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
